Training took: 9057.48003793 seconds

Training loss:
[ 3.36156468  3.27020586  3.28390804  3.29690941  3.28340709  3.31492682
  3.30193759  3.7539545   3.6205273   3.61702797  3.5940689   3.57917189
  3.58831922  3.62648621  3.60672718  3.58743193  3.4528734   3.50871215
  3.51731857  3.54290944  3.51719303  3.53701315  3.53637718  3.55177577
  4.32699535  3.3763929   3.32070574  3.30638263  3.35342985  3.30630574
  3.34434344  3.33832587  3.3601884   3.27555884  3.32881281  3.32914252
  3.38594385  3.338119    3.37017293  3.35623159  4.24616392  3.81101487
  3.59450028  3.52830252  3.52698556  3.63340393  3.59452682  3.46219167
  3.49916584  3.58688223  3.5753184   3.45017645  3.47799504  3.50772504
  3.45389944  3.4931743   3.44064823  3.96117061  3.82822648  3.8155114
  3.79121617  3.74939508  3.7801221   3.82384319  3.8100057   3.82187475
  3.80839373  3.86203741  3.82627879  3.86651904  3.80890828  3.82369776
  3.8059845   4.14123538  5.31844549  3.63365688  3.54867955  3.5249074
  3.59943676  3.51447372  3.56078817  3.56586005  3.58720375  3.52848082
  3.5537253   3.55017248  3.59876694  3.55550176  3.59908773  3.55360326
  4.74568742  4.00454973  3.82699533  3.74386212  3.72945598  3.86332574
  3.80351997  3.67308406  3.70781025  3.80962104]
Validation loss:
[ 3.4517808   3.43242049  3.496207    3.46278596  3.45263076  3.48573279
  3.48224926  3.57458329  3.52374029  3.58208656  3.5371449   3.55966043
  3.52479148  3.56741285  3.54590297  3.4737432   3.49930048  3.50592422
  3.55280757  3.54639101  3.51542521  3.48942494  3.52540112  4.34650803
  3.79256892  3.55195951  3.54533219  3.47414494  3.53785276  3.58935142
  3.55048943  3.47155476  3.55224776  3.56179118  3.57782173  3.60343647
  3.53939939  3.55040789  3.52650571  3.56005406  3.76031947  3.59771252
  3.55071163  3.59820914  3.60869169  3.57212424  3.54420781  3.57096744
  3.53058219  3.64631367  3.68256974  3.54704523  3.67180777  3.56523871
  3.54942012  3.57079792  3.67441201  3.73870206  3.76723504  3.75014067
  3.75824475  3.73680401  3.76852608  3.75181103  3.80932593  3.76588297
  3.77600741  3.76341891  3.83113813  3.75978756  3.83996606  3.8326714
  3.846488    4.22239876  4.44338894  3.78689814  3.72502565  3.75602436
  3.79747009  3.73447037  3.77384353  3.81451559  3.77847838  3.78520012
  3.75107598  3.86601901  3.76261878  3.78011155  3.79008651  3.78647733
  3.95173311  3.73879719  3.77942562  3.84368753  3.79463458  3.80977583
  3.76787853  3.7768805   3.76017809  3.87166309]
Test Loss: (0.16, 0.39000000000000001)